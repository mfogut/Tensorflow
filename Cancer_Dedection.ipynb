{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Input(shape=30))\n",
    "model.add(Dense(units=1, activation='sigmoid') )\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n",
      "Epoch 1/500\n",
      "381/381 [==============================] - 1s 2ms/sample - loss: 0.4381 - accuracy: 0.8320 - val_loss: 0.4015 - val_accuracy: 0.8723\n",
      "Epoch 2/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.3981 - accuracy: 0.8583 - val_loss: 0.3679 - val_accuracy: 0.8936\n",
      "Epoch 3/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.3648 - accuracy: 0.8845 - val_loss: 0.3395 - val_accuracy: 0.9043\n",
      "Epoch 4/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.3362 - accuracy: 0.9003 - val_loss: 0.3162 - val_accuracy: 0.9202\n",
      "Epoch 5/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.3129 - accuracy: 0.9160 - val_loss: 0.2963 - val_accuracy: 0.9309\n",
      "Epoch 6/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.2935 - accuracy: 0.9213 - val_loss: 0.2792 - val_accuracy: 0.9362\n",
      "Epoch 7/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.2762 - accuracy: 0.9265 - val_loss: 0.2645 - val_accuracy: 0.9415\n",
      "Epoch 8/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.2615 - accuracy: 0.9265 - val_loss: 0.2519 - val_accuracy: 0.9468\n",
      "Epoch 9/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.2488 - accuracy: 0.9370 - val_loss: 0.2405 - val_accuracy: 0.9468\n",
      "Epoch 10/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.2375 - accuracy: 0.9396 - val_loss: 0.2304 - val_accuracy: 0.9468\n",
      "Epoch 11/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.2275 - accuracy: 0.9423 - val_loss: 0.2213 - val_accuracy: 0.9521\n",
      "Epoch 12/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.2186 - accuracy: 0.9423 - val_loss: 0.2132 - val_accuracy: 0.9521\n",
      "Epoch 13/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.2105 - accuracy: 0.9449 - val_loss: 0.2057 - val_accuracy: 0.9521\n",
      "Epoch 14/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.2031 - accuracy: 0.9449 - val_loss: 0.1988 - val_accuracy: 0.9574\n",
      "Epoch 15/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1964 - accuracy: 0.9449 - val_loss: 0.1926 - val_accuracy: 0.9574\n",
      "Epoch 16/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.1903 - accuracy: 0.9475 - val_loss: 0.1869 - val_accuracy: 0.9574\n",
      "Epoch 17/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.1848 - accuracy: 0.9475 - val_loss: 0.1814 - val_accuracy: 0.9574\n",
      "Epoch 18/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1794 - accuracy: 0.9475 - val_loss: 0.1766 - val_accuracy: 0.9574\n",
      "Epoch 19/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1747 - accuracy: 0.9554 - val_loss: 0.1720 - val_accuracy: 0.9574\n",
      "Epoch 20/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1704 - accuracy: 0.9554 - val_loss: 0.1677 - val_accuracy: 0.9574\n",
      "Epoch 21/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.1662 - accuracy: 0.9554 - val_loss: 0.1636 - val_accuracy: 0.9574\n",
      "Epoch 22/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1626 - accuracy: 0.9606 - val_loss: 0.1597 - val_accuracy: 0.9574\n",
      "Epoch 23/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1588 - accuracy: 0.9606 - val_loss: 0.1562 - val_accuracy: 0.9574\n",
      "Epoch 24/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1555 - accuracy: 0.9633 - val_loss: 0.1528 - val_accuracy: 0.9574\n",
      "Epoch 25/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1524 - accuracy: 0.9633 - val_loss: 0.1497 - val_accuracy: 0.9574\n",
      "Epoch 26/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1495 - accuracy: 0.9633 - val_loss: 0.1467 - val_accuracy: 0.9574\n",
      "Epoch 27/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1466 - accuracy: 0.9633 - val_loss: 0.1440 - val_accuracy: 0.9574\n",
      "Epoch 28/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1441 - accuracy: 0.9659 - val_loss: 0.1413 - val_accuracy: 0.9574\n",
      "Epoch 29/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1417 - accuracy: 0.9659 - val_loss: 0.1387 - val_accuracy: 0.9574\n",
      "Epoch 30/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1394 - accuracy: 0.9685 - val_loss: 0.1362 - val_accuracy: 0.9574\n",
      "Epoch 31/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1372 - accuracy: 0.9685 - val_loss: 0.1339 - val_accuracy: 0.9628\n",
      "Epoch 32/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1351 - accuracy: 0.9685 - val_loss: 0.1317 - val_accuracy: 0.9628\n",
      "Epoch 33/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.1331 - accuracy: 0.9711 - val_loss: 0.1296 - val_accuracy: 0.9628\n",
      "Epoch 34/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1312 - accuracy: 0.9711 - val_loss: 0.1276 - val_accuracy: 0.9681\n",
      "Epoch 35/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1295 - accuracy: 0.9711 - val_loss: 0.1257 - val_accuracy: 0.9681\n",
      "Epoch 36/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.1277 - accuracy: 0.9738 - val_loss: 0.1239 - val_accuracy: 0.9681\n",
      "Epoch 37/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1262 - accuracy: 0.9738 - val_loss: 0.1221 - val_accuracy: 0.9681\n",
      "Epoch 38/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1247 - accuracy: 0.9738 - val_loss: 0.1203 - val_accuracy: 0.9681\n",
      "Epoch 39/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1231 - accuracy: 0.9764 - val_loss: 0.1187 - val_accuracy: 0.9681\n",
      "Epoch 40/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1217 - accuracy: 0.9764 - val_loss: 0.1172 - val_accuracy: 0.9681\n",
      "Epoch 41/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1203 - accuracy: 0.9764 - val_loss: 0.1157 - val_accuracy: 0.9681\n",
      "Epoch 42/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1191 - accuracy: 0.9764 - val_loss: 0.1143 - val_accuracy: 0.9681\n",
      "Epoch 43/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1178 - accuracy: 0.9764 - val_loss: 0.1128 - val_accuracy: 0.9681\n",
      "Epoch 44/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.1166 - accuracy: 0.9764 - val_loss: 0.1115 - val_accuracy: 0.9681\n",
      "Epoch 45/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1155 - accuracy: 0.9764 - val_loss: 0.1102 - val_accuracy: 0.9681\n",
      "Epoch 46/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1144 - accuracy: 0.9764 - val_loss: 0.1089 - val_accuracy: 0.9734\n",
      "Epoch 47/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1133 - accuracy: 0.9764 - val_loss: 0.1077 - val_accuracy: 0.9734\n",
      "Epoch 48/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1123 - accuracy: 0.9764 - val_loss: 0.1065 - val_accuracy: 0.9734\n",
      "Epoch 49/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1113 - accuracy: 0.9764 - val_loss: 0.1054 - val_accuracy: 0.9734\n",
      "Epoch 50/500\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.96 - 0s 97us/sample - loss: 0.1104 - accuracy: 0.9764 - val_loss: 0.1043 - val_accuracy: 0.9734\n",
      "Epoch 51/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1094 - accuracy: 0.9790 - val_loss: 0.1032 - val_accuracy: 0.9734\n",
      "Epoch 52/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1085 - accuracy: 0.9790 - val_loss: 0.1022 - val_accuracy: 0.9734\n",
      "Epoch 53/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.1077 - accuracy: 0.9790 - val_loss: 0.1011 - val_accuracy: 0.9787\n",
      "Epoch 54/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.1069 - accuracy: 0.9790 - val_loss: 0.1002 - val_accuracy: 0.9734\n",
      "Epoch 55/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1061 - accuracy: 0.9790 - val_loss: 0.0992 - val_accuracy: 0.9787\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1053 - accuracy: 0.9790 - val_loss: 0.0983 - val_accuracy: 0.9787\n",
      "Epoch 57/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1045 - accuracy: 0.9816 - val_loss: 0.0975 - val_accuracy: 0.9787\n",
      "Epoch 58/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1037 - accuracy: 0.9816 - val_loss: 0.0966 - val_accuracy: 0.9787\n",
      "Epoch 59/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1031 - accuracy: 0.9816 - val_loss: 0.0957 - val_accuracy: 0.9787\n",
      "Epoch 60/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.1024 - accuracy: 0.9816 - val_loss: 0.0950 - val_accuracy: 0.9787\n",
      "Epoch 61/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.1018 - accuracy: 0.9816 - val_loss: 0.0941 - val_accuracy: 0.9787\n",
      "Epoch 62/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.1011 - accuracy: 0.9816 - val_loss: 0.0933 - val_accuracy: 0.9787\n",
      "Epoch 63/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.1004 - accuracy: 0.9816 - val_loss: 0.0926 - val_accuracy: 0.9787\n",
      "Epoch 64/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0998 - accuracy: 0.9816 - val_loss: 0.0919 - val_accuracy: 0.9787\n",
      "Epoch 65/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0992 - accuracy: 0.9816 - val_loss: 0.0912 - val_accuracy: 0.9787\n",
      "Epoch 66/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0986 - accuracy: 0.9816 - val_loss: 0.0905 - val_accuracy: 0.9787\n",
      "Epoch 67/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0980 - accuracy: 0.9816 - val_loss: 0.0898 - val_accuracy: 0.9787\n",
      "Epoch 68/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0975 - accuracy: 0.9816 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
      "Epoch 69/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0970 - accuracy: 0.9816 - val_loss: 0.0885 - val_accuracy: 0.9787\n",
      "Epoch 70/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0964 - accuracy: 0.9816 - val_loss: 0.0878 - val_accuracy: 0.9787\n",
      "Epoch 71/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0959 - accuracy: 0.9816 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
      "Epoch 72/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0954 - accuracy: 0.9816 - val_loss: 0.0866 - val_accuracy: 0.9787\n",
      "Epoch 73/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0949 - accuracy: 0.9816 - val_loss: 0.0861 - val_accuracy: 0.9787\n",
      "Epoch 74/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0944 - accuracy: 0.9816 - val_loss: 0.0855 - val_accuracy: 0.9787\n",
      "Epoch 75/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0939 - accuracy: 0.9816 - val_loss: 0.0849 - val_accuracy: 0.9787\n",
      "Epoch 76/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0935 - accuracy: 0.9816 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
      "Epoch 77/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0930 - accuracy: 0.9816 - val_loss: 0.0838 - val_accuracy: 0.9787\n",
      "Epoch 78/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0926 - accuracy: 0.9816 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
      "Epoch 79/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0922 - accuracy: 0.9816 - val_loss: 0.0828 - val_accuracy: 0.9787\n",
      "Epoch 80/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0917 - accuracy: 0.9816 - val_loss: 0.0823 - val_accuracy: 0.9787\n",
      "Epoch 81/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0913 - accuracy: 0.9816 - val_loss: 0.0818 - val_accuracy: 0.9787\n",
      "Epoch 82/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0910 - accuracy: 0.9816 - val_loss: 0.0813 - val_accuracy: 0.9787\n",
      "Epoch 83/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0905 - accuracy: 0.9816 - val_loss: 0.0808 - val_accuracy: 0.9787\n",
      "Epoch 84/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0901 - accuracy: 0.9816 - val_loss: 0.0804 - val_accuracy: 0.9787\n",
      "Epoch 85/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0898 - accuracy: 0.9816 - val_loss: 0.0800 - val_accuracy: 0.9787\n",
      "Epoch 86/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0894 - accuracy: 0.9816 - val_loss: 0.0795 - val_accuracy: 0.9787\n",
      "Epoch 87/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0890 - accuracy: 0.9816 - val_loss: 0.0790 - val_accuracy: 0.9787\n",
      "Epoch 88/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0887 - accuracy: 0.9816 - val_loss: 0.0786 - val_accuracy: 0.9840\n",
      "Epoch 89/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0883 - accuracy: 0.9816 - val_loss: 0.0783 - val_accuracy: 0.9787\n",
      "Epoch 90/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0880 - accuracy: 0.9816 - val_loss: 0.0778 - val_accuracy: 0.9840\n",
      "Epoch 91/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0876 - accuracy: 0.9816 - val_loss: 0.0774 - val_accuracy: 0.9840\n",
      "Epoch 92/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0873 - accuracy: 0.9816 - val_loss: 0.0771 - val_accuracy: 0.9840\n",
      "Epoch 93/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0870 - accuracy: 0.9816 - val_loss: 0.0766 - val_accuracy: 0.9840\n",
      "Epoch 94/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0866 - accuracy: 0.9816 - val_loss: 0.0763 - val_accuracy: 0.9840\n",
      "Epoch 95/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0864 - accuracy: 0.9816 - val_loss: 0.0760 - val_accuracy: 0.9840\n",
      "Epoch 96/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0860 - accuracy: 0.9816 - val_loss: 0.0756 - val_accuracy: 0.9840\n",
      "Epoch 97/500\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 1.00 - 0s 94us/sample - loss: 0.0857 - accuracy: 0.9816 - val_loss: 0.0752 - val_accuracy: 0.9840\n",
      "Epoch 98/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0854 - accuracy: 0.9816 - val_loss: 0.0749 - val_accuracy: 0.9840\n",
      "Epoch 99/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0851 - accuracy: 0.9816 - val_loss: 0.0745 - val_accuracy: 0.9840\n",
      "Epoch 100/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0848 - accuracy: 0.9816 - val_loss: 0.0742 - val_accuracy: 0.9840\n",
      "Epoch 101/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0845 - accuracy: 0.9816 - val_loss: 0.0739 - val_accuracy: 0.9840\n",
      "Epoch 102/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0843 - accuracy: 0.9816 - val_loss: 0.0736 - val_accuracy: 0.9840\n",
      "Epoch 103/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0840 - accuracy: 0.9816 - val_loss: 0.0733 - val_accuracy: 0.9840\n",
      "Epoch 104/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0837 - accuracy: 0.9816 - val_loss: 0.0729 - val_accuracy: 0.9840\n",
      "Epoch 105/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0834 - accuracy: 0.9816 - val_loss: 0.0727 - val_accuracy: 0.9840\n",
      "Epoch 106/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0832 - accuracy: 0.9816 - val_loss: 0.0724 - val_accuracy: 0.9840\n",
      "Epoch 107/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0830 - accuracy: 0.9816 - val_loss: 0.0721 - val_accuracy: 0.9840\n",
      "Epoch 108/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0826 - accuracy: 0.9816 - val_loss: 0.0718 - val_accuracy: 0.9840\n",
      "Epoch 109/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0824 - accuracy: 0.9816 - val_loss: 0.0715 - val_accuracy: 0.9840\n",
      "Epoch 110/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0821 - accuracy: 0.9816 - val_loss: 0.0713 - val_accuracy: 0.9840\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0819 - accuracy: 0.9816 - val_loss: 0.0710 - val_accuracy: 0.9840\n",
      "Epoch 112/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0817 - accuracy: 0.9816 - val_loss: 0.0707 - val_accuracy: 0.9840\n",
      "Epoch 113/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0814 - accuracy: 0.9816 - val_loss: 0.0705 - val_accuracy: 0.9840\n",
      "Epoch 114/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0812 - accuracy: 0.9816 - val_loss: 0.0702 - val_accuracy: 0.9840\n",
      "Epoch 115/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0809 - accuracy: 0.9816 - val_loss: 0.0700 - val_accuracy: 0.9840\n",
      "Epoch 116/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0807 - accuracy: 0.9816 - val_loss: 0.0697 - val_accuracy: 0.9840\n",
      "Epoch 117/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0805 - accuracy: 0.9816 - val_loss: 0.0694 - val_accuracy: 0.9840\n",
      "Epoch 118/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0803 - accuracy: 0.9816 - val_loss: 0.0692 - val_accuracy: 0.9840\n",
      "Epoch 119/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0800 - accuracy: 0.9816 - val_loss: 0.0690 - val_accuracy: 0.9840\n",
      "Epoch 120/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0798 - accuracy: 0.9816 - val_loss: 0.0688 - val_accuracy: 0.9840\n",
      "Epoch 121/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0796 - accuracy: 0.9816 - val_loss: 0.0685 - val_accuracy: 0.9840\n",
      "Epoch 122/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0794 - accuracy: 0.9816 - val_loss: 0.0683 - val_accuracy: 0.9840\n",
      "Epoch 123/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0792 - accuracy: 0.9843 - val_loss: 0.0681 - val_accuracy: 0.9840\n",
      "Epoch 124/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0790 - accuracy: 0.9843 - val_loss: 0.0679 - val_accuracy: 0.9840\n",
      "Epoch 125/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0788 - accuracy: 0.9843 - val_loss: 0.0676 - val_accuracy: 0.9840\n",
      "Epoch 126/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0786 - accuracy: 0.9843 - val_loss: 0.0674 - val_accuracy: 0.9840\n",
      "Epoch 127/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0784 - accuracy: 0.9843 - val_loss: 0.0673 - val_accuracy: 0.9840\n",
      "Epoch 128/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0782 - accuracy: 0.9843 - val_loss: 0.0670 - val_accuracy: 0.9840\n",
      "Epoch 129/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0780 - accuracy: 0.9869 - val_loss: 0.0668 - val_accuracy: 0.9840\n",
      "Epoch 130/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0778 - accuracy: 0.9869 - val_loss: 0.0666 - val_accuracy: 0.9840\n",
      "Epoch 131/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0777 - accuracy: 0.9869 - val_loss: 0.0665 - val_accuracy: 0.9840\n",
      "Epoch 132/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0774 - accuracy: 0.9869 - val_loss: 0.0663 - val_accuracy: 0.9840\n",
      "Epoch 133/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0773 - accuracy: 0.9869 - val_loss: 0.0660 - val_accuracy: 0.9840\n",
      "Epoch 134/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0771 - accuracy: 0.9869 - val_loss: 0.0659 - val_accuracy: 0.9840\n",
      "Epoch 135/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0769 - accuracy: 0.9869 - val_loss: 0.0657 - val_accuracy: 0.9840\n",
      "Epoch 136/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0768 - accuracy: 0.9869 - val_loss: 0.0655 - val_accuracy: 0.9840\n",
      "Epoch 137/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0765 - accuracy: 0.9869 - val_loss: 0.0654 - val_accuracy: 0.9840\n",
      "Epoch 138/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0764 - accuracy: 0.9869 - val_loss: 0.0652 - val_accuracy: 0.9840\n",
      "Epoch 139/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0762 - accuracy: 0.9869 - val_loss: 0.0650 - val_accuracy: 0.9840\n",
      "Epoch 140/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0760 - accuracy: 0.9869 - val_loss: 0.0648 - val_accuracy: 0.9840\n",
      "Epoch 141/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0759 - accuracy: 0.9869 - val_loss: 0.0647 - val_accuracy: 0.9840\n",
      "Epoch 142/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0757 - accuracy: 0.9869 - val_loss: 0.0645 - val_accuracy: 0.9840\n",
      "Epoch 143/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0755 - accuracy: 0.9869 - val_loss: 0.0643 - val_accuracy: 0.9840\n",
      "Epoch 144/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0754 - accuracy: 0.9869 - val_loss: 0.0642 - val_accuracy: 0.9840\n",
      "Epoch 145/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0753 - accuracy: 0.9869 - val_loss: 0.0640 - val_accuracy: 0.9840\n",
      "Epoch 146/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0751 - accuracy: 0.9869 - val_loss: 0.0639 - val_accuracy: 0.9840\n",
      "Epoch 147/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0749 - accuracy: 0.9869 - val_loss: 0.0637 - val_accuracy: 0.9840\n",
      "Epoch 148/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0748 - accuracy: 0.9869 - val_loss: 0.0635 - val_accuracy: 0.9840\n",
      "Epoch 149/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0746 - accuracy: 0.9869 - val_loss: 0.0635 - val_accuracy: 0.9840\n",
      "Epoch 150/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0744 - accuracy: 0.9869 - val_loss: 0.0633 - val_accuracy: 0.9840\n",
      "Epoch 151/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0743 - accuracy: 0.9869 - val_loss: 0.0632 - val_accuracy: 0.9840\n",
      "Epoch 152/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0742 - accuracy: 0.9869 - val_loss: 0.0630 - val_accuracy: 0.9840\n",
      "Epoch 153/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0740 - accuracy: 0.9869 - val_loss: 0.0629 - val_accuracy: 0.9840\n",
      "Epoch 154/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0739 - accuracy: 0.9869 - val_loss: 0.0627 - val_accuracy: 0.9840\n",
      "Epoch 155/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0737 - accuracy: 0.9869 - val_loss: 0.0626 - val_accuracy: 0.9840\n",
      "Epoch 156/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0736 - accuracy: 0.9869 - val_loss: 0.0624 - val_accuracy: 0.9840\n",
      "Epoch 157/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0734 - accuracy: 0.9869 - val_loss: 0.0623 - val_accuracy: 0.9840\n",
      "Epoch 158/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0733 - accuracy: 0.9869 - val_loss: 0.0621 - val_accuracy: 0.9840\n",
      "Epoch 159/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0732 - accuracy: 0.9869 - val_loss: 0.0620 - val_accuracy: 0.9840\n",
      "Epoch 160/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0730 - accuracy: 0.9869 - val_loss: 0.0619 - val_accuracy: 0.9840\n",
      "Epoch 161/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0729 - accuracy: 0.9869 - val_loss: 0.0618 - val_accuracy: 0.9840\n",
      "Epoch 162/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0728 - accuracy: 0.9869 - val_loss: 0.0616 - val_accuracy: 0.9840\n",
      "Epoch 163/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0726 - accuracy: 0.9869 - val_loss: 0.0615 - val_accuracy: 0.9840\n",
      "Epoch 164/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0725 - accuracy: 0.9869 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
      "Epoch 165/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0724 - accuracy: 0.9869 - val_loss: 0.0613 - val_accuracy: 0.9840\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0722 - accuracy: 0.9869 - val_loss: 0.0612 - val_accuracy: 0.9840\n",
      "Epoch 167/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0721 - accuracy: 0.9869 - val_loss: 0.0610 - val_accuracy: 0.9840\n",
      "Epoch 168/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0720 - accuracy: 0.9869 - val_loss: 0.0609 - val_accuracy: 0.9840\n",
      "Epoch 169/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0719 - accuracy: 0.9869 - val_loss: 0.0608 - val_accuracy: 0.9840\n",
      "Epoch 170/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0718 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
      "Epoch 171/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0716 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
      "Epoch 172/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0715 - accuracy: 0.9869 - val_loss: 0.0606 - val_accuracy: 0.9840\n",
      "Epoch 173/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0713 - accuracy: 0.9869 - val_loss: 0.0604 - val_accuracy: 0.9840\n",
      "Epoch 174/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0712 - accuracy: 0.9869 - val_loss: 0.0603 - val_accuracy: 0.9840\n",
      "Epoch 175/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0711 - accuracy: 0.9869 - val_loss: 0.0602 - val_accuracy: 0.9840\n",
      "Epoch 176/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0710 - accuracy: 0.9843 - val_loss: 0.0601 - val_accuracy: 0.9840\n",
      "Epoch 177/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0709 - accuracy: 0.9843 - val_loss: 0.0600 - val_accuracy: 0.9840\n",
      "Epoch 178/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0708 - accuracy: 0.9843 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
      "Epoch 179/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0707 - accuracy: 0.9843 - val_loss: 0.0598 - val_accuracy: 0.9840\n",
      "Epoch 180/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0705 - accuracy: 0.9843 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
      "Epoch 181/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0705 - accuracy: 0.9843 - val_loss: 0.0595 - val_accuracy: 0.9840\n",
      "Epoch 182/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0703 - accuracy: 0.9843 - val_loss: 0.0595 - val_accuracy: 0.9840\n",
      "Epoch 183/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0702 - accuracy: 0.9843 - val_loss: 0.0593 - val_accuracy: 0.9840\n",
      "Epoch 184/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0701 - accuracy: 0.9843 - val_loss: 0.0593 - val_accuracy: 0.9840\n",
      "Epoch 185/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0700 - accuracy: 0.9843 - val_loss: 0.0592 - val_accuracy: 0.9840\n",
      "Epoch 186/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0699 - accuracy: 0.9843 - val_loss: 0.0591 - val_accuracy: 0.9840\n",
      "Epoch 187/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0698 - accuracy: 0.9843 - val_loss: 0.0590 - val_accuracy: 0.9840\n",
      "Epoch 188/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0697 - accuracy: 0.9843 - val_loss: 0.0590 - val_accuracy: 0.9840\n",
      "Epoch 189/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0696 - accuracy: 0.9843 - val_loss: 0.0588 - val_accuracy: 0.9840\n",
      "Epoch 190/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0695 - accuracy: 0.9843 - val_loss: 0.0587 - val_accuracy: 0.9840\n",
      "Epoch 191/500\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.00 - 0s 94us/sample - loss: 0.0694 - accuracy: 0.9843 - val_loss: 0.0586 - val_accuracy: 0.9840\n",
      "Epoch 192/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0693 - accuracy: 0.9843 - val_loss: 0.0586 - val_accuracy: 0.9840\n",
      "Epoch 193/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0692 - accuracy: 0.9843 - val_loss: 0.0584 - val_accuracy: 0.9840\n",
      "Epoch 194/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0690 - accuracy: 0.9843 - val_loss: 0.0584 - val_accuracy: 0.9840\n",
      "Epoch 195/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0689 - accuracy: 0.9843 - val_loss: 0.0584 - val_accuracy: 0.9840\n",
      "Epoch 196/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0688 - accuracy: 0.9843 - val_loss: 0.0583 - val_accuracy: 0.9840\n",
      "Epoch 197/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0688 - accuracy: 0.9843 - val_loss: 0.0582 - val_accuracy: 0.9840\n",
      "Epoch 198/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0687 - accuracy: 0.9843 - val_loss: 0.0581 - val_accuracy: 0.9840\n",
      "Epoch 199/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0686 - accuracy: 0.9843 - val_loss: 0.0580 - val_accuracy: 0.9840\n",
      "Epoch 200/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0685 - accuracy: 0.9843 - val_loss: 0.0579 - val_accuracy: 0.9840\n",
      "Epoch 201/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0684 - accuracy: 0.9843 - val_loss: 0.0578 - val_accuracy: 0.9840\n",
      "Epoch 202/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0683 - accuracy: 0.9843 - val_loss: 0.0578 - val_accuracy: 0.9840\n",
      "Epoch 203/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0682 - accuracy: 0.9843 - val_loss: 0.0577 - val_accuracy: 0.9840\n",
      "Epoch 204/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0681 - accuracy: 0.9843 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 205/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0680 - accuracy: 0.9843 - val_loss: 0.0575 - val_accuracy: 0.9840\n",
      "Epoch 206/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0679 - accuracy: 0.9843 - val_loss: 0.0574 - val_accuracy: 0.9840\n",
      "Epoch 207/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0678 - accuracy: 0.9843 - val_loss: 0.0574 - val_accuracy: 0.9840\n",
      "Epoch 208/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0677 - accuracy: 0.9843 - val_loss: 0.0572 - val_accuracy: 0.9840\n",
      "Epoch 209/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0677 - accuracy: 0.9843 - val_loss: 0.0572 - val_accuracy: 0.9840\n",
      "Epoch 210/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0676 - accuracy: 0.9843 - val_loss: 0.0572 - val_accuracy: 0.9840\n",
      "Epoch 211/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0675 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9840\n",
      "Epoch 212/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0674 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9840\n",
      "Epoch 213/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0673 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9840\n",
      "Epoch 214/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0672 - accuracy: 0.9843 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
      "Epoch 215/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0672 - accuracy: 0.9843 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
      "Epoch 216/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0670 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9840\n",
      "Epoch 217/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0669 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9840\n",
      "Epoch 218/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0668 - accuracy: 0.9843 - val_loss: 0.0566 - val_accuracy: 0.9840\n",
      "Epoch 219/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0668 - accuracy: 0.9869 - val_loss: 0.0566 - val_accuracy: 0.9840\n",
      "Epoch 220/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0667 - accuracy: 0.9869 - val_loss: 0.0565 - val_accuracy: 0.9840\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0667 - accuracy: 0.9843 - val_loss: 0.0565 - val_accuracy: 0.9840\n",
      "Epoch 222/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0665 - accuracy: 0.9843 - val_loss: 0.0564 - val_accuracy: 0.9840\n",
      "Epoch 223/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0664 - accuracy: 0.9843 - val_loss: 0.0564 - val_accuracy: 0.9840\n",
      "Epoch 224/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0664 - accuracy: 0.9843 - val_loss: 0.0563 - val_accuracy: 0.9840\n",
      "Epoch 225/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0663 - accuracy: 0.9869 - val_loss: 0.0563 - val_accuracy: 0.9840\n",
      "Epoch 226/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0662 - accuracy: 0.9869 - val_loss: 0.0562 - val_accuracy: 0.9840\n",
      "Epoch 227/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0661 - accuracy: 0.9869 - val_loss: 0.0562 - val_accuracy: 0.9840\n",
      "Epoch 228/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.0561 - val_accuracy: 0.9840\n",
      "Epoch 229/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.0560 - val_accuracy: 0.9840\n",
      "Epoch 230/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0659 - accuracy: 0.9869 - val_loss: 0.0559 - val_accuracy: 0.9840\n",
      "Epoch 231/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0658 - accuracy: 0.9869 - val_loss: 0.0559 - val_accuracy: 0.9840\n",
      "Epoch 232/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0658 - accuracy: 0.9869 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 233/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0657 - accuracy: 0.9869 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 234/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0656 - accuracy: 0.9869 - val_loss: 0.0557 - val_accuracy: 0.9840\n",
      "Epoch 235/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0655 - accuracy: 0.9869 - val_loss: 0.0557 - val_accuracy: 0.9840\n",
      "Epoch 236/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0655 - accuracy: 0.9869 - val_loss: 0.0556 - val_accuracy: 0.9840\n",
      "Epoch 237/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0654 - accuracy: 0.9869 - val_loss: 0.0556 - val_accuracy: 0.9840\n",
      "Epoch 238/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0652 - accuracy: 0.9869 - val_loss: 0.0555 - val_accuracy: 0.9840\n",
      "Epoch 239/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0652 - accuracy: 0.9869 - val_loss: 0.0555 - val_accuracy: 0.9840\n",
      "Epoch 240/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0652 - accuracy: 0.9869 - val_loss: 0.0554 - val_accuracy: 0.9840\n",
      "Epoch 241/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0650 - accuracy: 0.9869 - val_loss: 0.0554 - val_accuracy: 0.9840\n",
      "Epoch 242/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0650 - accuracy: 0.9869 - val_loss: 0.0553 - val_accuracy: 0.9840\n",
      "Epoch 243/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0649 - accuracy: 0.9869 - val_loss: 0.0552 - val_accuracy: 0.9840\n",
      "Epoch 244/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.0551 - val_accuracy: 0.9840\n",
      "Epoch 245/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.0551 - val_accuracy: 0.9840\n",
      "Epoch 246/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0647 - accuracy: 0.9869 - val_loss: 0.0551 - val_accuracy: 0.9840\n",
      "Epoch 247/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0646 - accuracy: 0.9869 - val_loss: 0.0550 - val_accuracy: 0.9840\n",
      "Epoch 248/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0646 - accuracy: 0.9869 - val_loss: 0.0550 - val_accuracy: 0.9840\n",
      "Epoch 249/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0645 - accuracy: 0.9869 - val_loss: 0.0549 - val_accuracy: 0.9840\n",
      "Epoch 250/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0644 - accuracy: 0.9869 - val_loss: 0.0549 - val_accuracy: 0.9840\n",
      "Epoch 251/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.0549 - val_accuracy: 0.9840\n",
      "Epoch 252/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.0549 - val_accuracy: 0.9840\n",
      "Epoch 253/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0642 - accuracy: 0.9869 - val_loss: 0.0549 - val_accuracy: 0.9840\n",
      "Epoch 254/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.0548 - val_accuracy: 0.9840\n",
      "Epoch 255/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.0547 - val_accuracy: 0.9840\n",
      "Epoch 256/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0640 - accuracy: 0.9869 - val_loss: 0.0547 - val_accuracy: 0.9840\n",
      "Epoch 257/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0640 - accuracy: 0.9869 - val_loss: 0.0546 - val_accuracy: 0.9840\n",
      "Epoch 258/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0639 - accuracy: 0.9869 - val_loss: 0.0546 - val_accuracy: 0.9840\n",
      "Epoch 259/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0638 - accuracy: 0.9869 - val_loss: 0.0545 - val_accuracy: 0.9840\n",
      "Epoch 260/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0638 - accuracy: 0.9869 - val_loss: 0.0545 - val_accuracy: 0.9840\n",
      "Epoch 261/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0637 - accuracy: 0.9869 - val_loss: 0.0545 - val_accuracy: 0.9840\n",
      "Epoch 262/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
      "Epoch 263/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
      "Epoch 264/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0635 - accuracy: 0.9869 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
      "Epoch 265/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0635 - accuracy: 0.9869 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
      "Epoch 266/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.0543 - val_accuracy: 0.9840\n",
      "Epoch 267/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0633 - accuracy: 0.9869 - val_loss: 0.0542 - val_accuracy: 0.9840\n",
      "Epoch 268/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0632 - accuracy: 0.9869 - val_loss: 0.0542 - val_accuracy: 0.9840\n",
      "Epoch 269/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0632 - accuracy: 0.9869 - val_loss: 0.0541 - val_accuracy: 0.9840\n",
      "Epoch 270/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0631 - accuracy: 0.9869 - val_loss: 0.0541 - val_accuracy: 0.9840\n",
      "Epoch 271/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0631 - accuracy: 0.9869 - val_loss: 0.0541 - val_accuracy: 0.9840\n",
      "Epoch 272/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.0540 - val_accuracy: 0.9840\n",
      "Epoch 273/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0629 - accuracy: 0.9869 - val_loss: 0.0540 - val_accuracy: 0.9840\n",
      "Epoch 274/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0629 - accuracy: 0.9869 - val_loss: 0.0540 - val_accuracy: 0.9840\n",
      "Epoch 275/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0628 - accuracy: 0.9869 - val_loss: 0.0540 - val_accuracy: 0.9840\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0627 - accuracy: 0.9869 - val_loss: 0.0540 - val_accuracy: 0.9840\n",
      "Epoch 277/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0627 - accuracy: 0.9869 - val_loss: 0.0539 - val_accuracy: 0.9840\n",
      "Epoch 278/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0626 - accuracy: 0.9869 - val_loss: 0.0539 - val_accuracy: 0.9840\n",
      "Epoch 279/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0626 - accuracy: 0.9869 - val_loss: 0.0538 - val_accuracy: 0.9840\n",
      "Epoch 280/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.0538 - val_accuracy: 0.9840\n",
      "Epoch 281/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.0538 - val_accuracy: 0.9840\n",
      "Epoch 282/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0624 - accuracy: 0.9869 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 283/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0623 - accuracy: 0.9869 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 284/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0623 - accuracy: 0.9869 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 285/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 286/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 287/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0621 - accuracy: 0.9869 - val_loss: 0.0536 - val_accuracy: 0.9840\n",
      "Epoch 288/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0621 - accuracy: 0.9869 - val_loss: 0.0536 - val_accuracy: 0.9840\n",
      "Epoch 289/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0620 - accuracy: 0.9869 - val_loss: 0.0536 - val_accuracy: 0.9840\n",
      "Epoch 290/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.0536 - val_accuracy: 0.9840\n",
      "Epoch 291/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.0535 - val_accuracy: 0.9840\n",
      "Epoch 292/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.0535 - val_accuracy: 0.9840\n",
      "Epoch 293/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 294/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0617 - accuracy: 0.9869 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 295/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0617 - accuracy: 0.9869 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 296/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 297/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 298/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0615 - accuracy: 0.9869 - val_loss: 0.0533 - val_accuracy: 0.9840\n",
      "Epoch 299/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0615 - accuracy: 0.9869 - val_loss: 0.0533 - val_accuracy: 0.9840\n",
      "Epoch 300/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0533 - val_accuracy: 0.9840\n",
      "Epoch 301/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 302/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0613 - accuracy: 0.9869 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 303/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0613 - accuracy: 0.9869 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 304/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 305/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 306/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 307/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0610 - accuracy: 0.9869 - val_loss: 0.0531 - val_accuracy: 0.9840\n",
      "Epoch 308/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0610 - accuracy: 0.9869 - val_loss: 0.0531 - val_accuracy: 0.9840\n",
      "Epoch 309/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.0531 - val_accuracy: 0.9840\n",
      "Epoch 310/500\n",
      "381/381 [==============================] - 0s 115us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.0531 - val_accuracy: 0.9840\n",
      "Epoch 311/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.0530 - val_accuracy: 0.9840\n",
      "Epoch 312/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0608 - accuracy: 0.9869 - val_loss: 0.0530 - val_accuracy: 0.9840\n",
      "Epoch 313/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
      "Epoch 314/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
      "Epoch 315/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0606 - accuracy: 0.9869 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
      "Epoch 316/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0606 - accuracy: 0.9869 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
      "Epoch 317/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
      "Epoch 318/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
      "Epoch 319/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0604 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
      "Epoch 320/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0604 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
      "Epoch 321/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
      "Epoch 322/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
      "Epoch 323/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 324/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0602 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 325/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0602 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
      "Epoch 326/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 327/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 328/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0600 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 329/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0600 - accuracy: 0.9869 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
      "Epoch 330/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
      "Epoch 332/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
      "Epoch 333/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 334/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
      "Epoch 335/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
      "Epoch 336/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.0526 - val_accuracy: 0.9840\n",
      "Epoch 337/500\n",
      "381/381 [==============================] - 0s 107us/sample - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 338/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 339/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 340/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 341/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 342/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 343/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 344/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 345/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0592 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 346/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0592 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 347/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 348/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 349/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 350/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 351/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0590 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 352/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 353/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 354/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0588 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 355/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 356/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0588 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 357/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 358/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 359/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 360/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 361/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 362/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0585 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 363/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0585 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 364/500\n",
      "381/381 [==============================] - 0s 105us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 365/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 366/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 367/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 368/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 369/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 370/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0582 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 371/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0582 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 372/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 373/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 374/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 375/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 376/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 377/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0579 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 378/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9894\n",
      "Epoch 379/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0579 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 380/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 381/500\n",
      "381/381 [==============================] - 0s 92us/sample - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 382/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0577 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 383/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0577 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 384/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0576 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 385/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0576 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0576 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 387/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0576 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 388/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0575 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 389/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 390/500\n",
      "381/381 [==============================] - 0s 102us/sample - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 391/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 392/500\n",
      "381/381 [==============================] - 0s 110us/sample - loss: 0.0573 - accuracy: 0.9869 - val_loss: 0.0520 - val_accuracy: 0.9840\n",
      "Epoch 393/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0573 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 394/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0573 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 395/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 396/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 397/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 398/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0572 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 399/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0571 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 400/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0570 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 401/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0570 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 402/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0570 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 403/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0570 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 404/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0569 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 405/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0569 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 406/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0568 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 407/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0568 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 408/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0568 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 409/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 410/500\n",
      "381/381 [==============================] - 0s 94us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 411/500\n",
      "381/381 [==============================] - 0s 99us/sample - loss: 0.0566 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 412/500\n",
      "381/381 [==============================] - 0s 97us/sample - loss: 0.0566 - accuracy: 0.9869 - val_loss: 0.0522 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x191e1686f88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 500, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "381/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 42us/sample - loss: 0.0611 - accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score :  [0.05655676941937349, 0.98687667]\n"
     ]
    }
   ],
   "source": [
    "print('Train score : ', model.evaluate(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 48us/sample - loss: 0.0635 - accuracy: 0.9840\n",
      "Test Score :  [0.05220842218779503, 0.9840425]\n"
     ]
    }
   ],
   "source": [
    "print('Test Score : ',model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438091</td>\n",
       "      <td>0.832021</td>\n",
       "      <td>0.401531</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.398095</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.367916</td>\n",
       "      <td>0.893617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.364753</td>\n",
       "      <td>0.884514</td>\n",
       "      <td>0.339540</td>\n",
       "      <td>0.904255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336224</td>\n",
       "      <td>0.900262</td>\n",
       "      <td>0.316191</td>\n",
       "      <td>0.920213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.312897</td>\n",
       "      <td>0.916010</td>\n",
       "      <td>0.296278</td>\n",
       "      <td>0.930851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.052165</td>\n",
       "      <td>0.984043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.984043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.056685</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.052233</td>\n",
       "      <td>0.984043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.056646</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.052225</td>\n",
       "      <td>0.984043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.056619</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.052208</td>\n",
       "      <td>0.984043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.438091  0.832021  0.401531      0.872340\n",
       "1    0.398095  0.858268  0.367916      0.893617\n",
       "2    0.364753  0.884514  0.339540      0.904255\n",
       "3    0.336224  0.900262  0.316191      0.920213\n",
       "4    0.312897  0.916010  0.296278      0.930851\n",
       "..        ...       ...       ...           ...\n",
       "407  0.056757  0.986877  0.052165      0.984043\n",
       "408  0.056711  0.986877  0.052174      0.984043\n",
       "409  0.056685  0.986877  0.052233      0.984043\n",
       "410  0.056646  0.986877  0.052225      0.984043\n",
       "411  0.056619  0.986877  0.052208      0.984043\n",
       "\n",
       "[412 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x191edc539c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxV5Z348c/3brnZICxhS1iCUFkVbEStI+6KWtG2zgxuo3Zh/LVO7XT0p7Ydbe10arU/bTvFbazT2uqgVdtSpS61oNgqEhBEQBaRJWyBAAkJubnb9/fHOQk34YbckOUm937fr9d93XOe85xzvzni93nuc849j6gqxhhjMpcn3QEYY4zpXpbojTEmw1miN8aYDGeJ3hhjMpwlemOMyXCW6I0xJsP5UqkkIrOAnwJe4AlVva+NelcBvwVOVdUKERkDrAPWu1XeVdWbj/VZgwcP1jFjxqQUvDHGGMfy5cv3qWpxsm3tJnoR8QLzgAuBSmCZiCxQ1bWt6hUCXweWtjrEx6o6LdVgx4wZQ0VFRarVjTHGACKyta1tqQzdzAA2qepmVQ0D84ErktT7PnA/EDquKI0xxnSLVBJ9CbA9Yb3SLWsmItOBkar6UpL9y0TkfRF5U0TOOv5QjTHGHI9UxuglSVnzcxNExAM8BNyYpN4uYJSqVovIp4Hfi8hkVa1t8QEic4G5AKNGjUoxdGOMMalIJdFXAiMT1kuBnQnrhcAUYLGIAAwDFojIbFWtABoBVHW5iHwMfApoMQivqo8DjwOUl5fbw3eMyUKRSITKykpCIRv9PZZgMEhpaSl+vz/lfVJJ9MuA8SJSBuwA5gDXNG1U1RpgcNO6iCwGbnPvuikG9qtqTETGAuOBzSlHZ4zJGpWVlRQWFjJmzBjcTqNpRVWprq6msrKSsrKylPdrd4xeVaPALcCrOLdKPqeqa0TkXhGZ3c7uM4EPRGQV8Dxws6ruTzk6Y0zWCIVCDBo0yJL8MYgIgwYN6vC3npTuo1fVhcDCVmV3t1H3nITlF4AXOhSRMSZrWZJv3/Gco4z5ZWxdY5QHX9/Ayu0H0x2KMaaPKigoSHcI3SJjEn04Gudnb2xk5bYD6Q7FGGN6lYxJ9Ll+LwANkXiaIzHG9HWqyu23386UKVOYOnUqzz77LAC7du1i5syZTJs2jSlTprBkyRJisRg33nhjc92HHnoozdEfLaUx+r4gx+e0WaFILM2RGGP6uhdffJGVK1eyatUq9u3bx6mnnsrMmTN55plnuPjii/n2t79NLBbj8OHDrFy5kh07dvDhhx8CcPBg7xs+zphE7/EIAZ+HUNQSvTF93ff+uIa1O2vbr9gBk0b0457LJ6dU9+233+bqq6/G6/UydOhQzj77bJYtW8app57KF7/4RSKRCFdeeSXTpk1j7NixbN68mX/5l3/hsssu46KLLurSuLtCxgzdAAR9Hhpt6MYY00mqyX+3OXPmTN566y1KSkq4/vrreeqppxgwYACrVq3inHPOYd68eXz5y1/u4WjblzE9eoDcgJeGsPXojenrUu15d5eZM2fy2GOPccMNN7B//37eeustHnjgAbZu3UpJSQlf+cpXqK+vZ8WKFVx66aUEAgG+8IUvcMIJJ3DjjTemNfZkMirRB/1eG7oxxnTa5z73Od555x1OPvlkRIT777+fYcOG8atf/YoHHngAv99PQUEBTz31FDt27OCmm24iHndGE374wx+mOfqjSVtfUdKlvLxcj/d59Bc/9BZjBufx2PXlXRyVMaa7rVu3jokTJ6Y7jD4h2bkSkeWqmjT5ZdYYvd9DyMbojTGmhQxL9F4a7PZKY4xpIeMSfaMlemOMaSHDEr0N3RhjTGsZlehz7a4bY4w5SkYl+qDfa49AMMaYVjIu0dsPpowxpqWMSvQ5fg+hqI3RG2O637GeXb9lyxamTJnSg9EcW0qJXkRmich6EdkkInceo95VIqIiUp5Qdpe733oRubgrgm5Lrt9LOBonHu9dPwIzxph0ajfRi4gXmAdcAkwCrhaRSUnqFQJfB5YmlE3CmUx8MjALeNg9XrcIus+kb7RevTGmg+644w4efvjh5vXvfve7fO973+P888/nlFNOYerUqfzhD3/o8HFDoRA33XQTU6dOZfr06SxatAiANWvWMGPGDKZNm8ZJJ53Exo0bqa+v57LLLuPkk09mypQpzc/B76xUnnUzA9ikqpsBRGQ+cAWwtlW97wP3A7cllF0BzFfVRuATEdnkHu+dzgZ+lMP7+cKKG1jlOY+GyIXkBrqtPTHGdLc/3Qm7V3ftMYdNhUvua3PznDlz+MY3vsFXv/pVAJ577jleeeUV/vVf/5V+/fqxb98+Tj/9dGbPnt2heVvnzZsHwOrVq/noo4+46KKL2LBhA48++ii33nor1157LeFwmFgsxsKFCxkxYgQvv/wyADU1NZ34g49IZeimBNiesF7pljUTkenASFV9qaP7dhnxUFyzmhFSbXfeGGM6bPr06VRVVbFz505WrVrFgAEDGD58ON/61rc46aSTuOCCC9ixYwd79uzp0HHffvttrr/+egAmTJjA6NGj2bBhA2eccQb/+Z//yY9+9CO2bt1Kbm4uU6dO5c9//jN33HEHS5YsoX///l3yt6XSo0/WdDUPgouIB3gIuLGj+yYcYy4wF2DUqFEphJREIB+AXBrtMQjG9HXH6Hl3p6uuuornn3+e3bt3M2fOHJ5++mn27t3L8uXL8fv9jBkzhlAo1KFjtvXgyGuuuYbTTjuNl19+mYsvvpgnnniC8847j+XLl7Nw4ULuuusuLrroIu6+++5O/12p9OgrgZEJ66XAzoT1QmAKsFhEtgCnAwvcC7Lt7QuAqj6uquWqWl5cXNyxv6CJ109c/ORJo91iaYw5LnPmzGH+/Pk8//zzXHXVVdTU1DBkyBD8fj+LFi1i69atHT7mzJkzefrppwHYsGED27Zt48QTT2Tz5s2MHTuWr3/968yePZsPPviAnTt3kpeXx3XXXcdtt93GihUruuTvSqVHvwwYLyJlwA6ci6vXNG1U1RpgcNO6iCwGblPVChFpAJ4RkQeBEcB44L0uiTyJuD+X3Egjhy3RG2OOw+TJkzl06BAlJSUMHz6ca6+9lssvv5zy8nKmTZvGhAkTOnzMr371q9x8881MnToVn8/HL3/5S3Jycnj22Wf5zW9+g9/vZ9iwYdx9990sW7aM22+/HY/Hg9/v55FHHumSvyul59GLyKXATwAv8KSq/kBE7gUqVHVBq7qLcRO9u/5t4ItAFPiGqv7pWJ/VmefRh+8/kd/VTmDI9f/NuScOOa5jGGPSw55Hn7qOPo8+pRmmVHUhsLBVWdKBI1U9p9X6D4AfpPI5nebPI09CHG60Hr0xxjTJqKkECeSRSyP7w9F0R2KMyQKrV69uvqOmSU5ODkuXLm1jj/TIqEQvgXzyOERloyV6Y0z3mzp1KitXrkx3GO3KqGfdeHPyyZNG6u1irDF9Um+bw7o3Op5zlFGJXnLyyaORwzZ0Y0yfEwwGqa6utmR/DKpKdXU1wWCwQ/tl1tCNP598TyP1djHWmD6ntLSUyspK9u7dm+5QerVgMEhpaWmH9smoRN90MdZ69Mb0PX6/n7KysnSHkZEyaugGv5PobYzeGGOOyKxEH8h3nnUTCqc7EmOM6TUyK9H78wCINDakORBjjOk9MivRu0+wjIfr0hyIMcb0HpmV6N0evTYeTnMgxhjTe2RWond79FiP3hhjmmVWos9xZmX3ROrTHIgxxvQemZXoA4UAeCN19us6Y4xxZVaid3v0eYRojMbTHIwxxvQOmZXoA06iL5AG6u0JlsYYA6SY6EVkloisF5FNInJnku03i8hqEVkpIm+LyCS3fIyINLjlK0Xk0a7+A1rIcYZu8gnZdILGGONq91k3IuIF5gEX4kz2vUxEFqjq2oRqz6jqo2792cCDwCx328eqOq1rw26D26PPJ0S9Pe/GGGOA1Hr0M4BNqrpZVcPAfOCKxAqqWpuwmg+k50qoL0Dc43eHbqxHb4wxkFqiLwG2J6xXumUtiMjXRORj4H7g6wmbykTkfRF5U0TO6lS0KYj5C9yhG+vRG2MMpJboJUnZUT12VZ2nqicAdwDfcYt3AaNUdTrwTeAZEel31AeIzBWRChGp6OyzqDVQQL716I0xplkqib4SGJmwXgrsPEb9+cCVAKraqKrV7vJy4GPgU613UNXHVbVcVcuLi4tTjT25QAEF1qM3xphmqST6ZcB4ESkTkQAwB1iQWEFExiesXgZsdMuL3Yu5iMhYYDywuSsCb1NOIQU02DPpjTHG1e5dN6oaFZFbgFcBL/Ckqq4RkXuBClVdANwiIhcAEeAAcIO7+0zgXhGJAjHgZlXd3x1/SBNPsJB82cdhu4/eGGOAFKcSVNWFwMJWZXcnLN/axn4vAC90JsCO8gYLKSBkPXpjjHFl1i9jAckpoEBC1qM3xhhXxiV6gkX0k8PWozfGGFdGJvo8QhwOhdIdiTHG9AqZl+hziwCIH+7Wa77GGNNnZF6iDzqJXhoOpjkQY4zpHTIv0bs9eizRG2MMkImJ3u3Re8OW6I0xBjIx0bs9el+4tp2KxhiTHTIw0Q9w3mKHCNt0gsYYk4GJPtgfgP7UcygUSXMwxhiTfpmX6L1+It48+ks9h0L261hjjMm8RA/EcvrTn3pqrUdvjDGZmejjOf0pknpqG6xHb4wxGZnonefdWI/eGGMgQxO9J28A/ann4GFL9MYYk5GJ3pc/gP5Sz4HD4XSHYowxaZehiX4g/annQL0lemOMSSnRi8gsEVkvIptE5M4k228WkdUislJE3haRSQnb7nL3Wy8iF3dl8G0KFpEnjdTU1/fIxxljTG/WbqJ3J/eeB1wCTAKuTkzkrmdUdaqqTgPuBx50952EM5n4ZGAW8HDTZOHdyn0MQuMhe1SxMcak0qOfAWxS1c2qGgbmA1ckVlDVxAfL5APqLl8BzFfVRlX9BNjkHq97uY9BiNZZojfGmFQmBy8BtiesVwKnta4kIl8DvgkEgPMS9n231b4lxxVpR7hPsNSGA93+UcYY09ul0qOXJGV6VIHqPFU9AbgD+E5H9hWRuSJSISIVe/fuTSGkdrhDNxKq6fyxjDGmj0sl0VcCIxPWS4Gdx6g/H7iyI/uq6uOqWq6q5cXFxSmE1A63Rx+I1NIYtUnCjTHZLZVEvwwYLyJlIhLAubi6ILGCiIxPWL0M2OguLwDmiEiOiJQB44H3Oh92O/IHATBIajlQbz+aMsZkt3bH6FU1KiK3AK8CXuBJVV0jIvcCFaq6ALhFRC4AIsAB4AZ33zUi8hywFogCX1PV7u9iB4uIe/wMlhr214cZ1j/Y7R9pjDG9VSoXY1HVhcDCVmV3Jyzfeox9fwD84HgDPC4iRIKDKY7U2K9jjTFZLyN/GQug+UMYjNOjN8aYbJaxid5TOITBYj16Y4zJ2ETv6zeUwVJDdZ0lemNMdsvYRO8pdBL9wfpQukMxxpi0ythET/4QfMQJHapOdyTGGJNWmZvoC5wfXmndnjQHYowx6ZXBiX4oAJ76fWkOxBhj0itzE33+EAC8h7vg2TnGGNOHZW6id4duguF9RGLxNAdjjDHpk7mJPlhETPwMpoaqQ43pjsYYY9ImcxO9CJHcwQymht01doulMSZ7ZW6iBzS/mGKpYU+tJXpjTPbK6ETvdX80ZT16Y0w2y+hE7y8awTA5YD16Y0xWy+hEL0UjnefdHLQpBY0x2SujEz39nVkMowe2t1PRGGMyV1Ykeu+hyjQHYowx6ZNSoheRWSKyXkQ2icidSbZ/U0TWisgHIvKGiIxO2BYTkZXua0HrfbtVkZPocw/vRFV79KONMaa3aDfRi4gXmAdcAkwCrhaRSa2qvQ+Uq+pJwPPA/QnbGlR1mvua3UVxp6ZwBHHxMiReRW1DtEc/2hhjeotUevQzgE2qullVw8B84IrECqq6SFUPu6vvAqVdG+Zx8voIBYdQIvvYbXfeGGOyVCqJvgRIvJpZ6Za15UvAnxLWgyJSISLvisiVxxFjp8QKSyi1RG+MyWK+FOpIkrKkA94ich1QDpydUDxKVXeKyFjgLyKyWlU/brXfXGAuwKhRo1IKPFXegaMp2fMmSw42dOlxjTGmr0ilR18JjExYLwV2tq4kIhcA3wZmq2rzU8RUdaf7vhlYDExvva+qPq6q5apaXlxc3KE/oD3BwWMYxn627avt0uMaY0xfkUqiXwaMF5EyEQkAc4AWd8+IyHTgMZwkX5VQPkBEctzlwcCZwNquCj4VnqKR+CRObZXdS2+MyU7tDt2oalREbgFeBbzAk6q6RkTuBSpUdQHwAFAA/FZEALa5d9hMBB4TkThOo3KfqvZoom+6lz6yf2uPfqwxxvQWqYzRo6oLgYWtyu5OWL6gjf3+BkztTICdVuSM+Xtrt6OquA2RMcZkjcz+ZSzAgDHE8TA8WsnBw5F0R2OMMT0u8xO9L0Aov5Sxsout+w+3X98YYzJM5id6ID5oHGNlN9ss0RtjslBWJPrgsBMpk11s23co3aEYY0yPy4pE7yseT66EObjH7rwxxmSfrEj0DB4PgO7bmOZAjDGm52VHoh80DgD/wU/SHIgxxvS87Ej0hcOJeHMZGt7G/vpwuqMxxpgelR2JXoRQvzLGyi427LELssaY7JIdiR7wDZ3AOM8OS/TGmKyTNYk+WHoyJVLN9h070h2KMcb0qKxJ9DJsCgCRHavTHIkxxvSsrEn0DDsJgLwD62yicGNMVsmeRF8whIbAIMqim9l7qLH9+sYYkyGyJ9EDoUGTmOTZyke77YKsMSZ7ZFWizx05jXGyg7WV+9IdijHG9JiUEr2IzBKR9SKySUTuTLL9myKyVkQ+EJE3RGR0wrYbRGSj+7qhK4PvqODIaeRIlL2ffJjOMIwxpke1m+hFxAvMAy4BJgFXi8ikVtXeB8pV9STgeeB+d9+BwD3AacAM4B4RGdB14XeQe0HWs2tl2kIwxpielkqPfgawSVU3q2oYmA9ckVhBVRepatPD3t8FSt3li4HXVXW/qh4AXgdmdU3ox2HQOBp9hZSF1lJdZxdkjTHZIZVEXwJsT1ivdMva8iXgT8e5b/fyeGgYMp3pno2s3lGTtjCMMaYnpZLok82mnfRGdBG5DigHHujIviIyV0QqRKRi7969KYR0/HLHns6JUsm6LTu79XOMMaa3SCXRVwIjE9ZLgaOypIhcAHwbmK2qjR3ZV1UfV9VyVS0vLi5ONfbjkjPmNDyi1H+ytFs/xxhjeotUEv0yYLyIlIlIAJgDLEisICLTgcdwknxVwqZXgYtEZIB7EfYityx9SsoByN2zgnjcfiFrjMl87SZ6VY0Ct+Ak6HXAc6q6RkTuFZHZbrUHgALgtyKyUkQWuPvuB76P01gsA+51y9Int4jagrFMjH7Ehir74ZQxJvP5UqmkqguBha3K7k5YvuAY+z4JPHm8AXYHz5gzKF/9Ii9u3MOEYf3SHY4xxnSrrPplbJOCCefTTxrY9ZGN0xtjMl9WJnrGzAQgf+dfbZzeGJPxsjPRFxRTU/gppkc/YN3u2nRHY4wx3So7Ez3gG3c2p3rW89f1dj+9MSazZW2iz59wPkGJsOfDxekOxRhjulXWJnrGnEVUApRWvcmhUCTd0RhjTLfJ3kSfU8ChEZ/hfKngrxu797ELxhiTTtmb6IHCaVcwyrOXdR+8l+5QjDGm22R1ovedeAkAgY9fIRqLpzkaY4zpHlmd6Ok3nIMDTmJm9B2WfpLeJzMYY0x3ye5ED+Sf8vdM9Wzh3ffsV7LGmMyU9Ynef/JVxBEKNrxIxIZvjDEZKOsTPf1GcGDIaVwUX8KbH1W1X98YY/oYS/RA/9Oupcyzh7ffei3doRhjTJezRA/4Js0mJn5G7XiZzXvr0h2OMcZ0KUv0ALlFRMZdxGzv33j6b5vSHY0xxnQpS/Su4Kk3MlhqObTiBeobo+kOxxhjukxKiV5EZonIehHZJCJ3Jtk+U0RWiEhURK5qtS3mTi/YPMVgrzTuAkL9ypijC/nd+zvSHY0xxnSZdhO9iHiBecAlwCTgahGZ1KraNuBG4Jkkh2hQ1Wnua3aS7b2Dx0POZ27mFM8mli55DVWbkMQYkxlS6dHPADap6mZVDQPzgSsSK6jqFlX9AOjTN6LLtGuI+PI5r/Z3vLVxX7rDMcaYLpFKoi8BtiesV7plqQqKSIWIvCsiV3Youp4W7Iecch2f9S7l16/+zXr1xpiMkEqilyRlHcmAo1S1HLgG+ImInHDUB4jMdRuDir170/vIYN/p/wevwJl7nubtTdarN8b0fakk+kpgZMJ6KZDy/HuqutN93wwsBqYnqfO4qparanlxcXGqh+4eA8vQk6/mWt8bPPHy28Rs8nBjTB+XSqJfBowXkTIRCQBzgJTunhGRASKS4y4PBs4E1h5vsD3Fe/bt+AQu2vdr5i/blu5wjDGmU9pN9KoaBW4BXgXWAc+p6hoRuVdEZgOIyKkiUgn8PfCYiKxxd58IVIjIKmARcJ+q9vpEz4DRSPlNzPEt4vlX3uBAfTjdERljzHGT3nbBsby8XCsqKtIdBtTvI/bTaSwOjefP037KDz9/UrojMsaYNonIcvd66FHsl7FtyR+Md+ZtnO9ZwZaKV1hi88oaY/ooS/THctrNaP+R/Efwae58bgU1hyPpjsgYYzrMEv2x+IPIrPs4Ib6Fzzc8zz0LPkx3RMYY02GW6Nsz8bMw+XN8w/871qx6j2eW2l04xpi+xRJ9Ki79MZ7cfjxa+CT3LlhFxRabSNwY03dYok9F/mDk0h9zQvgj7sl7kZt/s5zKA4fTHZUxxqTEEn2qpnwePn0TV0de5DPRpVz3xFKqakPpjsoYY9plib4jZt0Hw6fxYOBRcg9t5donllJd15juqIwx5pgs0XeEPwj/8BQ+r48XB/yMA/v3cv0v3uPgYfvlrDGm97JE31EDRsM//obcQ1t5beQv+aSqhi888jcbszfG9FqW6I/HmL+Dyx5k4K4lLJ64gL2HGvj8w3/jwx016Y7MGGOOYon+eH36BjjrNoZuepY3J/8Jr8AXHvkbLyyvTHdkxhjTgiX6zjjvO/CZf2HAml/xlymvMn1kf/7tt6v4999/SDjap2dVNMZkEF+6A+jTRODC70MsSu7SR3jmVOVHpTfx2JItLNuynweuOpmppf3THaUxJstZj76zRGDWD+GMW/As+2/uaniQJ687iQOHw1z58F+5/5WPCEVi6Y7SGJPFLNF3BRG46D/g/Hvgw+c5b/nXeP3mqXx+egkPL/6Yy362hMXrq9IdpTEmS6WU6EVkloisF5FNInJnku0zRWSFiERF5KpW224QkY3u64auCrzXEYGzvglXPAzb3qHfUxfywFkefvXFGURiyo3/s4zrf7GUtTtr0x2pMSbLtJvoRcQLzAMuASYBV4vIpFbVtgE3As+02ncgcA9wGjADuEdEBnQ+7F5s+rVw058gFoEnLuTshjd4/Zsz+ffPTuKDyhou+68l/Ntzq9hWbffdG2N6Rio9+hnAJlXdrKphYD5wRWIFVd2iqh8ArW81uRh4XVX3q+oB4HVgVhfE3buVlsPcxTBiOvzun8n5/Vf40qeLeOv2c/nKWWN56YOdnPv/FnPr/PdZXWn33htjulcqib4E2J6wXumWpaIz+/ZthUPhhj86t2Cu/QM8cib997zDty6dyJL/ey43fmYMb6yr4vKfv80/PPYOr63ZTSzeu+bvNcZkhlQSvSQpSzUjpbSviMwVkQoRqdi7N4PmZvX6YObt8KXXwZ8Lv7oc/ngrQ7x1/PtnJ/HOXefxncsmsuNAA3N/vZxzfryIn/9lI7tr7KmYxpiuk0qirwRGJqyXAjtTPH5K+6rq46parqrlxcXFKR66Dyk5Bf75LTj9a7Di1/Bfp8C7j1Lohy+fNZY3bz+HedecwsgBefz4tQ185r43uPF/3uOF5ZXUhmyeWmNM54jqsTvnIuIDNgDnAzuAZcA1qromSd1fAi+p6vPu+kBgOXCKW2UF8GlVbXOKpvLycq2oqOj4X9JXVH0Er9wJmxdB8QTnHvwTzmvevLW6nucqtvP793ey42ADAZ+Hcz5VzOUnj+D8iUPIC9hv3IwxRxOR5apannRbe4nePcClwE8AL/Ckqv5ARO4FKlR1gYicCvwOGACEgN2qOtnd94vAt9xD/UBV/+dYn5XxiR5AFdYvhFfugoNbYey5zhDP6M84t2kCqsr72w/y0qpdvLx6J3tqG8nxeTjjhEGce+IQzj1xCKMG5aX5DzHG9BadTvQ9KSsSfZNICCp+AW/9GBr2O3fpnHELTLrSGd93xePKe1v289qaPSxeX8XmffUAjC3O59wThzDzU8WUjx5Afo719o3JVpboe7vwYVj1DLzzMOz/GPqPhNNuhlP+CYL9jqq+ZV89i9ZXsWj9Xt7dXE04GsfrEaaU9Oe0soGcVjaQ8tED6Z/nT8MfY4xJB0v0fUU8DhtegXd+Dlv/Cjn9nGQ/Y64z4UkSh8NRKrYc4L1P9vPeJ/tZuf0g4VgcEZgwrB+nlQ1k+qgipo0sYtTAPESS3QhljOnrLNH3RTtWOAl/ze9BY1A2E6ZdCxMvh0B+m7uFIjFWbj/YnPiXbz1Ag/tQtaI8P1NL+jN5RH8mDi9k8oh+lA0uwOux5G9MX2eJvi87uB1W/S+sfBoObIFAAUy+Ek6+GkadAR7vMXePxuJs2FPHqsqDrNp+kFWVNWyqOkQk5vx3D/o9nDi0kHFDChk/tIBxxQWMH1pA6YA8awCM6UMs0WcCVdj2Drz/NKz5HUTqIW8wTLgUJlwOY88GX05KhwpH43y8t461O2tZu6uWj3bXsnFPHVWHGpvr5Pg8jC0uYNyQI8l/3JACxgzKJ+Czh54a09tYos80jXWw8TX46CXY8BqED0GgEMZfCOMugHHnQ+GwDh+2piHCpqo6Pq6qY2PVITZV1bGxqo7KAw3NdbweYfSgPMYVFzB6UB4lRbmMKMqlZEAupUV59Mv12XUAY9LAEn0mizbC5jfhoz/C+leg3n3u/ZDJziTmY86E0WdC/uDj/ojD4Sib99a7id9pADa5DUBjqykTC3J8jCgKUrjVQjMAAAw1SURBVOIm/5KiPEYUBSl1l4cU5uCxISFjupwl+mwRj8OeD+HjN2DzYtj+HkTcxyEXT0xI/H8HBZ1/1ISqsq8uzM6DDew42MCOA+57wnJNQ8tHOPi9wrD+bkNQlOc2BkGnEeiXw6D8AEV5Abs+YEwHWaLPVtEw7Hwftr4NW/4K2951xvbBuVd/6BQYOhmGTYGhU2FgWbsXdzuqrjHqNAQHGqg82NC8vMNd3l0bovU/QY/AwPwAg/JznPeCAIMLnEZgUEGOux5gYL6zXJhjw0XGWKI3jlgEdq2CLW/D7tVO73/fRuf2TQB/HgyZ6DYAU9wGYDIEu2+C80gszu6aEJUHGthX10h1XSP768Psqw9TXddIdV2Y6vow++oaORSKJj1GwOthUIHTIAzKz2luGJzGwm0kCtxGIj9A0N+1jZkxvYEletO2SAj2fuQk/d0fOu97PoSGA0fq9B/lJv2mbwBTYcCYLu/9t6cxGuNAfcRpEBIagn31zvt+t2xfndMwtL5+0KQgx9f8TWFQfoDCoJ/CoM99+Vu892tVlh/w2rcH0ysdK9Hbw1GynT8II6Y5ryaqULsT9qyBPavdBmCN86tddZOnxw9FI6FoFBSNPvI+wF0uGNr8gLaukuPzMqy/l2H9g+3WVVUOh2PNDcH+ujDV9U4jUO0uV9eF2XEwxKHQIQ6FohwKRWhv7hePOA3FkYag7Uai5fYjZfkBn12QNj3KevQmdZEGqFrn9PirP3aevHlwm/OqbzVhjC/oXAcoGnUk+ReNPtIo5A/u8oags5oah6akXxuKUtfoLDeVOe9RapOUNS1H22ktpKmxyPGl/G2iIMdHfo6P3ICXvICXXL+XoN9Ljs9j3zAMYD1601X8uc4kKiWnHL0tXO/8irc5+W+FA+7yzhUth4LAuR7Qr8S5379wmPMNoHAYFA53lguGQH4x5A7osQZBRMh3E2oq3xqSUVVCkXhzQ5GsITiy7UjZ3rpGNu+rby5r+uVy+zFDrv9I4s91G4Fcv5dgwEuu3+OsB9ztTa/E9YSGIy/Qcj034CXo8+Dz2o/k+jJL9KZrBPJhyATnlUyoFmq2H0n+B7dC7Q44tNu5DbRuD0STTKHo8TsJP3+wm/yHHFnOGwy5RRAsci4Y5w2EvEHgTd9TO0XESZQBL0OOfvBoSlSVxmg84VtDlPpG53U4HCMUidHgvkLhI8sN4fiRbeEYtQ0RqmqPrDeEYxyOxI5rbuKA10PQ7zmqEWjZqCRpRNx9Wjcqrd/t20n3skRvekawHwQnOxdzk1GFUI2T8A/tdoaC6qqcH4DV7XXW66ucGbrqqyAWPsZn9XcSfrB/q1dRy+Vcdz2nH+QUQE4h+PNbzAWQDiJC0E1+Qwq7/viRWDxJI+E2HG6DkbwhibVoSJrq14Yi7rZ4i20d/7sh6HOSf8DrIeDz4PcKAZ+XgFfcdac8L+ClX9BPjs9ZD/g8BLzeI8s+DzleD36ftCx3989ptd5iu9eTcddQLNGb3kHESby5RVB84rHrqkJjLdTvg9BBp4FoOOhM3lJf7TQKDQec8lAN1O46shxtOPaxAbw5zjeUppc/r+V6IN9pEAL5EMhzHjTXXKfALUtSJ43fNBL5vU7C7BfsvniavpU0pNBQOMtNjUSUhkiMcDROOBonEnOOE4nFm8vqGqNs3+980wknlLd3baQjfB45qnFoWs5p1TD4E7bnHFX/6MYnscFq3fgUBn2MHtT202mP++9JpZKIzAJ+ijOV4BOqel+r7TnAU8CngWrgH1V1i4iMAdYB692q76rqzV0TuslaIkd65h0VCTmNRFPib2ooGuuc8vBh50dl4XpnOVzn/Lo4XO8MNYXd5Yi7TZPfwpmUN+A2CMkaA7dB8Oc5D6fz5Trv/tw21oNHl3kD4PE5774cZzlNQyGJ30oG9NBnxuJKJBan0U38iY2Asx47ss3dntiANCbdJ2F7q22NkbjT2LS1fyze4WGyaSOL+P3Xzuzyc9NuohcRLzAPuBCoBJaJyAJVXZtQ7UvAAVUdJyJzgB8B/+hu+1hVp2FMb+APOq+CIZ0/lqrzrKFwfcsGoenV1BgkazQSX3W7E/ZpcI6ZyjeP9ojH+XbiCzjvXr/z2weP3132O8NUzeu+Iw1Fc3mgZZ3mxsTd3+M9sp/HC+IFj8d997Z697iNjze1uk3rLfbxJKnrlHs9XrziJej3QY7PqZvmMf9YXBMailjLRiaqRzU+Bd00HWgqR50BbFLVzQAiMh+4AkhM9FcA33WXnwd+LnZVxWQ6kSMNR/6grj22qnMdIhpyvoVEQ0cagGhjq/KQ00DEI86vn2Nh5/EX0RDEGp3lWCPEok6deNSp1/wecbZFQ0dvi4Vb1YscWe7It5l0kWQNSUJjAYA6f4uqu9z0jtNI+nKPlGvc/bsVkJY/Gmy+VV2b171ALpDb1Mhq3NncdIymz2067vCTYdyLXX4aUkn0JcD2hPVK4LS26qhqVERqgKZ/+WUi8j5QC3xHVZd0LmRjsoCIO0ST062PoOiUeNxpBOJNDUjMSVbxmPNYjRbvbnk8enRZW3Wb1uPR1Os275NiXQAkofcvLd9jYacRTawjTbeaqnMOmru0CX3b5n6uOPVi7nkST8JxEj5H3AaojSlDOyuVRJ+sZ9564KmtOruAUapaLSKfBn4vIpNVtbbFziJzgbkAo0aNSiEkY0zaeTzgCQCBdEdi2pHKryAqgZEJ66XAzrbqiIgP6A/sV9VGVa0GUNXlwMfAp1p/gKo+rqrlqlpeXNz5x+caY4w5IpVEvwwYLyJlIhIA5gALWtVZANzgLl8F/EVVVUSK3Yu5iMhYYDywuWtCN8YYk4p2h27cMfdbgFdxbq98UlXXiMi9QIWqLgB+AfxaRDYB+3EaA4CZwL0iEgViwM2qur87/hBjjDHJ2UPNjDEmAxzroWb2pCJjjMlwluiNMSbDWaI3xpgMZ4neGGMyXK+7GCsie4GtnTjEYGBfF4WTyew8pcbOU2rsPKWmO8/TaFVN+kOkXpfoO0tEKtq68myOsPOUGjtPqbHzlJp0nScbujHGmAxnid4YYzJcJib6x9MdQB9h5yk1dp5SY+cpNWk5Txk3Rm+MMaalTOzRG2OMSZAxiV5EZonIehHZJCJ3pjuedBKRJ0WkSkQ+TCgbKCKvi8hG932AWy4i8jP3vH0gIqekL/KeJSIjRWSRiKwTkTUicqtbbucqgYgEReQ9EVnlnqfvueVlIrLUPU/Puk+3RURy3PVN7vYx6Yy/p4mIV0TeF5GX3PW0n6eMSPQJ89peAkwCrhaRSemNKq1+CcxqVXYn8IaqjgfecNfBOWfj3ddc4JEeirE3iAL/pqoTgdOBr7n/buxctdQInKeqJwPTgFkicjrO3NAPuefpAM7c0ZAwhzTwkFsvm9wKrEtYT/95UtU+/wLOAF5NWL8LuCvdcaX5nIwBPkxYXw8Md5eHA+vd5ceAq5PVy7YX8AfgQjtXxzxHecAKnOlE9wE+t7z5/0GcR5qf4S773HqS7th76PyU4nQOzgNewpl9L+3nKSN69CSf17YkTbH0VkNVdReA+z7ELbdzB7hfm6cDS7FzdRR3OGIlUAW8jjNb3EFVjbpVEs9FizmkgcQ5pDPdT4D/CzTNnD6IXnCeMiXRpzKvrUku68+diBQALwDf0FbzGbeumqQsK86VqsZUdRpOj3UGMDFZNfc9K8+TiHwWqFJn2tTm4iRVe/w8ZUqiT2Ve22y3R0SGA7jvVW55Vp87EfHjJPmnVfVFt9jOVRtU9SCwGOeaRpE7RzS0PBdJ55Du2UjT4kxgtohsAebjDN/8hF5wnjIl0acyr222S5zX9wac8eim8n9y7yg5HahpGrbIdCIiONNgrlPVBxM22blK4M79XOQu5wIX4FxsXIQzRzQcfZ6OmkO65yJOD1W9S1VLVXUMTg76i6peS284T+m+eNGFF0EuBTbgjB1+O93xpPlc/C+wC4jg9Bq+hDP29waw0X0f6NYVnDuWPgZWA+Xpjr8Hz9Pf4XxV/gBY6b4utXN11Hk6CXjfPU8fAne75WOB94BNwG+BHLc86K5vcrePTfffkIZzdg7wUm85T/bLWGOMyXCZMnRjjDGmDZbojTEmw1miN8aYDGeJ3hhjMpwlemOMyXCW6I0xJsNZojfGmAxnid4YYzLc/wcMpwrsqjjWhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_loss['loss'], label='loss')\n",
    "plt.plot(model_loss['val_loss'], label = 'val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x191edb4dc48>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_loss['accuracy'], label='accuracy')\n",
    "plt.plot(model_loss['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66   1]\n",
      " [  2 119]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        67\n",
      "           1       0.99      0.98      0.99       121\n",
      "\n",
      "    accuracy                           0.98       188\n",
      "   macro avg       0.98      0.98      0.98       188\n",
      "weighted avg       0.98      0.98      0.98       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
